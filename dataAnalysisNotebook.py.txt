# -*- coding: utf-8 -*-
"""Untitled37.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1kHTFQALzMfL4foVbhoruLZbEhb2CPTJg
"""

import pandas as pd
import matplotlib.pyplot as plt

df = pd.read_csv('Data_Analysis_Donnees.csv', index_col=0, parse_dates=True, sep=";")
df.head()

from scipy.stats import pearsonr

"""Etude des corrélation entre les variables"""

all_corr = []
for i in range(11):
  x = df.iloc[:,i]
  r_list = []
  for j in range(11):
    y = df.iloc[:,j]
    coeff_pearson = pearsonr(x,y)
    print(coeff_pearson[0])
    r_list.append(coeff_pearson)
  all_corr.append(r_list)

"""Searborn"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
sns.set_theme(style="darkgrid")

classByHeight = df.iloc[:,[0,10]]
classByHeight = classByHeight.sort_values(by=['Class'])
sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(classByHeight.iloc[:,0]), hue="Class", size="Class", data=classByHeight);

classByLength = df.iloc[:,[1,10]]
classByLength = classByLength.sort_values(by=['Class'])
sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(classByLength.iloc[:,0]), hue="Class", size="Class", data=classByLength);

classByArea = df.iloc[:,[2,10]]
classByArea = classByArea.sort_values(by=['Class'])
sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(classByArea.iloc[:,0]), hue="Class", size="Class", data=classByArea);

classByEccen = df.iloc[:,[3,10]]
classByEccen = classByEccen.sort_values(by=['Class'])
sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(classByEccen.iloc[:,0]), hue="Class", size="Class", data=classByEccen);

classByAreaAndEccen = df.iloc[:,[2,3,10]]
classByAreaAndEccen = classByAreaAndEccen.sort_values(by=['Class'])
sns.relplot(x=list(classByAreaAndEccen.iloc[:,0]),y = list(classByAreaAndEccen.iloc[:,1]), hue="Class", size="Class", data=classByAreaAndEccen);

classByPblack = df.iloc[:,[4,10]]
classByPblack = classByPblack.sort_values(by=['Class'])
sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = classByPblack.iloc[:,0], hue="Class", size="Class", data=classByPblack);

classByPand = df.iloc[:,[5,10]]
classByPand = classByPand.sort_values(by=['Class'])
sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(classByPand.iloc[:,0]), hue="Class", size="Class", data=classByPand);

classByMean = df.iloc[:,[6,10]]
classByMean = classByMean.sort_values(by=['Class'])
g = sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(classByMean.iloc[:,0]), hue="Class", size="Class", data=classByMean)
g.set(ylim=(0, 600))

classByBpix = df.iloc[:,[7,10]]
classByBpix = classByBpix.sort_values(by=['Class'])
sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(classByBpix.iloc[:,0]), hue="Class", size="Class", data=classByBpix);

classByBand = df.iloc[:,[8,10]]
classByBand = classByBand.sort_values(by=['Class'])
sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(classByBand.iloc[:,0]), hue="Class", size="Class", data=classByBand);

classByWb = df.iloc[:,[9,10]]
classByWb = classByWb.sort_values(by=['Class'])
sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(classByWb.iloc[:,0]), hue="Class", size="Class", data=classByWb);

meanTimesEccen = classByMean.iloc[:,0] * classByEccen.iloc[:,0]
meanTimesEccenDf = pd.DataFrame(data=meanTimesEccen)
meanTimesEccenDf['Class'] = classByMean.iloc[:,1]
g = sns.relplot(x=[i for i in range(len(list(df.iloc[:,2])))],y = list(meanTimesEccenDf.iloc[:,0]), hue="Class", size="Class", data=meanTimesEccenDf)
g.set(ylim=(0, 20000))

import random
random.seed(21)
allElem = [i for i in range(len(list(df.iloc[:,2])))]
numElem = 4500
list_of_random_items = random.sample(allElem, numElem)
testItems = [x for x in allElem if x not in list_of_random_items]
x_train = df.iloc[list_of_random_items,:]
x_test = df.iloc[testItems,:]
y_train = x_train.iloc[:,-1]
y_test = x_test.iloc[:,-1]
y_train = y_train.to_frame()
y_test = y_test.to_frame()
del x_train['Class']
del x_test['Class']

x_train.head()

y_train.head()

y_train['Class'].value_counts(normalize=True) * 100

y_test['Class'].value_counts(normalize=True) * 100

"""KNN"""

from sklearn.neighbors import KNeighborsClassifier

all_percentages = []
for i in range(1,20):
  neigh = KNeighborsClassifier(n_neighbors=i)
  neigh.fit(x_train, y_train)
  predictions = neigh.predict(x_test)
  nbCorrect = 0
  for i in range(len(y_test)):
    if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
  nbCorrect = (nbCorrect/len(predictions))*100
  all_percentages.append(nbCorrect)
plt.scatter([i for i in range(1,20)],all_percentages)

"""Nearest Centroid"""

from sklearn.neighbors import NearestCentroid

all_percentages = []
shrink = [0, .2, 0.4, 0.6, 0.8,1,1.2,1.4]
for shrinkage in shrink:
  clf = NearestCentroid(shrink_threshold=shrinkage)
  clf = clf.fit(x_train, y_train)
  predictions = clf.predict(x_test)
  nbCorrect = 0
  for i in range(len(y_test)):
    if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
  nbCorrect = (nbCorrect/len(predictions))*100
  all_percentages.append(nbCorrect)
plt.scatter(shrink,all_percentages)

"""Tree"""

from sklearn import tree

all_percentages = []
clf = tree.DecisionTreeClassifier()
clf = clf.fit(x_train, y_train)
predictions = clf.predict(x_test)
nbCorrect = 0
for i in range(len(y_test)):
  if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
nbCorrect = (nbCorrect/len(predictions))*100
print(nbCorrect)

"""SVM"""

from sklearn import svm

all_percentages = []
clf = svm.SVC()
clf = clf.fit(x_train, y_train)
predictions = clf.predict(x_test)
nbCorrect = 0
for i in range(len(y_test)):
  if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
nbCorrect = (nbCorrect/len(predictions))*100
print(nbCorrect)

"""Neural Network"""

from sklearn.neural_network import MLPClassifier

fig, ax = plt.subplots(nrows=2, ncols=5,figsize=(20, 20))
line = 0
column = 0
for i in range(1,10):
  all_percentages = []
  for j in range(1,10):
    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(i, j), random_state=1)
    clf.fit(x_train, y_train)
    predictions = clf.predict(x_test)
    nbCorrect = 0
    for i in range(len(y_test)):
      if predictions[i] == y_test.iloc[i,0]:
        nbCorrect += 1
    nbCorrect = (nbCorrect/len(predictions))*100
    all_percentages.append(nbCorrect)
  ax[line,column].scatter([a for a in range(1,10)],all_percentages)
  ax[line,column].set(ylabel='Taux de réussite')
  column += 1
  if column>4:
    column = 0
    line += 1

"""Random Forest """

from sklearn.ensemble import RandomForestClassifier

all_percentages = []
n = 40
for i in range(1,n):
  clf = RandomForestClassifier(n_estimators=i)
  clf = clf.fit(x_train, y_train)
  predictions = clf.predict(x_test)
  nbCorrect = 0
  for i in range(len(y_test)):
    if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
  nbCorrect = (nbCorrect/len(predictions))*100
  all_percentages.append(nbCorrect)
plt.scatter([i for i in range(1,n)],all_percentages)

"""Ce modèle est le meilleur obtenu, séléction pour n=25"""

import pickle

clf = RandomForestClassifier(n_estimators=25)
clf = clf.fit(x_train, y_train)
pickle.dump(clf, open('model.pickle', 'wb'))
from google.colab import files
files.download('model.pickle')

clf.predict([[6,7,42,1.167,0.429,0.881,3.60,18,37,5]])

"""SGD Classifier"""

from sklearn.linear_model import SGDClassifier

clf = SGDClassifier(loss="hinge", penalty="l2", max_iter=5)
clf = clf.fit(x_train, y_train)
predictions = clf.predict(x_test)
nbCorrect = 0
for i in range(len(y_test)):
  if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
nbCorrect = (nbCorrect/len(predictions))*100
print(nbCorrect)

"""Modified Dataset """

del df['Length']
del df['P_Black']

random.seed(21)
allElem = [i for i in range(len(list(df.iloc[:,2])))]
numElem = 4500
list_of_random_items = random.sample(allElem, numElem)
testItems = [x for x in allElem if x not in list_of_random_items]
x_train = df.iloc[list_of_random_items,:]
x_test = df.iloc[testItems,:]
y_train = x_train.iloc[:,-1]
y_test = x_test.iloc[:,-1]
y_train = y_train.to_frame()
y_test = y_test.to_frame()
del x_train['Class']
del x_test['Class']

"""KNN"""

all_percentages = []
for i in range(1,20):
  neigh = KNeighborsClassifier(n_neighbors=i)
  neigh.fit(x_train, y_train)
  predictions = neigh.predict(x_test)
  nbCorrect = 0
  for i in range(len(y_test)):
    if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
  nbCorrect = (nbCorrect/len(predictions))*100
  all_percentages.append(nbCorrect)
plt.scatter([i for i in range(1,20)],all_percentages)

"""Centroid"""

all_percentages = []
shrink = [0, .2, 0.4, 0.6, 0.8,1,1.2,1.4]
for shrinkage in shrink:
  clf = NearestCentroid(shrink_threshold=shrinkage)
  clf = clf.fit(x_train, y_train)
  predictions = clf.predict(x_test)
  nbCorrect = 0
  for i in range(len(y_test)):
    if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
  nbCorrect = (nbCorrect/len(predictions))*100
  all_percentages.append(nbCorrect)
plt.scatter(shrink,all_percentages)

"""Tree"""

#Better
all_percentages = []
clf = tree.DecisionTreeClassifier()
clf = clf.fit(x_train, y_train)
predictions = clf.predict(x_test)
nbCorrect = 0
for i in range(len(y_test)):
  if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
nbCorrect = (nbCorrect/len(predictions))*100
print(nbCorrect)

"""SVM"""

all_percentages = []
clf = svm.SVC()
clf = clf.fit(x_train, y_train)
predictions = clf.predict(x_test)
nbCorrect = 0
for i in range(len(y_test)):
  if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
nbCorrect = (nbCorrect/len(predictions))*100
print(nbCorrect)

"""Neural Networks"""

fig, ax = plt.subplots(nrows=2, ncols=5,figsize=(20, 20))
line = 0
column = 0
for i in range(1,10):
  all_percentages = []
  for j in range(1,10):
    clf = MLPClassifier(solver='lbfgs', alpha=1e-5,hidden_layer_sizes=(i, j), random_state=1)
    clf.fit(x_train, y_train)
    predictions = clf.predict(x_test)
    nbCorrect = 0
    for i in range(len(y_test)):
      if predictions[i] == y_test.iloc[i,0]:
        nbCorrect += 1
    nbCorrect = (nbCorrect/len(predictions))*100
    all_percentages.append(nbCorrect)
  ax[line,column].scatter([a for a in range(1,10)],all_percentages)
  ax[line,column].set(ylabel='Taux de réussite')
  column += 1
  if column>4:
    column = 0
    line += 1

"""Random Forest"""

all_percentages = []
n = 40
for i in range(1,n):
  clf = RandomForestClassifier(n_estimators=i)
  clf = clf.fit(x_train, y_train)
  predictions = clf.predict(x_test)
  nbCorrect = 0
  for i in range(len(y_test)):
    if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
  nbCorrect = (nbCorrect/len(predictions))*100
  all_percentages.append(nbCorrect)
plt.scatter([i for i in range(1,n)],all_percentages)

"""SGD Classifier"""

#Better
clf = SGDClassifier(loss="hinge", penalty="l2", max_iter=5)
clf = clf.fit(x_train, y_train)
predictions = clf.predict(x_test)
nbCorrect = 0
for i in range(len(y_test)):
  if predictions[i] == y_test.iloc[i,0]:
      nbCorrect += 1
nbCorrect = (nbCorrect/len(predictions))*100
print(nbCorrect)

"""Test Avec ACP"""

from sklearn.decomposition import PCA

def createData(df):
  random.seed(21)
  allElem = [i for i in range(len(list(df.iloc[:,2])))]
  numElem = 4500
  list_of_random_items = random.sample(allElem, numElem)
  testItems = [x for x in allElem if x not in list_of_random_items]
  x_train = df.iloc[list_of_random_items,:]
  x_test = df.iloc[testItems,:]
  y_train = x_train.iloc[:,-1]
  y_test = x_test.iloc[:,-1]
  y_train = y_train.to_frame()
  y_test = y_test.to_frame()
  del x_train['Class']
  del x_test['Class']
  return x_train,y_train,x_test,y_test

all_percentages = []
for i in range(2,6):
  pca = PCA(n_components=i)
  pca.fit(df)
  x_train,y_train,x_test,y_test = createData(df)
  percentages = []
  for j in range(1,40):
    clf = RandomForestClassifier(n_estimators=j)
    clf = clf.fit(x_train, y_train)
    predictions = clf.predict(x_test)
    nbCorrect = 0
    for k in range(len(y_test)):
      if predictions[k] == y_test.iloc[k,0]:
        nbCorrect += 1
    nbCorrect = (nbCorrect/len(predictions))*100
    percentages.append(nbCorrect)
  all_percentages.append(percentages)

i = 2
for percentages in all_percentages:
  plt.plot([a for a  in range(1,40)], percentages, label = "ndim pca = "+str(i))
  plt.legend()
  i += 1

data = [[2,6,7,42,1.167,0.429,0.881,3.60,18,37,5]]
print(len(data[0]))